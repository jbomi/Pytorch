{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20.07.30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Captum helps me understand how the data features impact your model predictions or neuron activations, shedding light on how your model operates.  \n",
    "Using Captum, I can apply a wid range of state-of-the-art feature attribution algorithms such as **Guided GradCam** and **Integrated Gradients** in a unified way.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to use Captum to: * attribute the predictions of an image classifier to their corresponding image features. * visualize the attribution results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "model=torchvision.models.resnet18(pretrained=True).eval()\n",
    "\n",
    "response=requests.get(\"https://image.freepik.com/free-photo/two-beautiful-puppies-cat-dog_58409-6024.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20.07.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=Image.open(BytesIO(response.content))\n",
    "\n",
    "center_crop=transforms.Compose([transforms.Resize(256),\n",
    "                               transforms.CenterCrop(224)])\n",
    "\n",
    "normalize=transforms.Compose([transforms.ToTensor(),\n",
    "                             transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                 std=[0.229,0.224,0.225])])\n",
    "#ToTensor(): converts the image to a tensor with values between 0 and 1\n",
    "#Normalize(): normalize to follow 0-centered imagenet pixel rgb distribution\n",
    "\n",
    "input_img=normalize(center_crop(img)).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the top-3 predictions of the models are classes 208 and 283 which correspond to dog and cat. Let us attribute each of these prdictions to the corresponding part of the input, **using Captum's Occlusion algorithm.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from captum.attr import Occlusion\n",
    "\n",
    "occlusion=Occlusion(model)\n",
    "\n",
    "strides=(3,9,9) #smaller=mort fine-grained attribution vut slower\n",
    "target=208 #Labrador(래브라도 리트리버?) index in ImageNet\n",
    "sliding_window_shapes=(3,45,45) \n",
    "# choose size enough to change object appearance\n",
    "baselines=0 \n",
    "#values to occlude the image with. 0 corresponds to gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20.08.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribution_dog=occlusion.attribute(input_img,\n",
    "                                   strides=strides,\n",
    "                                   target=target,\n",
    "                                   sliding_window_shapes=sliding_window_shapes,\n",
    "                                   baselines=baselines)\n",
    "target=283\n",
    "attribution_cat=occlusion.attribute(input_img,\n",
    "                                   strides=strides,\n",
    "                                   target=target,\n",
    "                                   sliding_window_shapes=sliding_window_shapes,\n",
    "                                   baselines=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides Occlusion, Captum features many algorithms such as Integrated Gradients, Deconvolution, GuidedBackprop, Guided GradCam, DeepLift, and GradientShap. All of these algorithms are **subclasses of Attribution**  \n",
    "which  \n",
    "1. expects your model as a callable forward_func upon initialization  \n",
    "2. has an attribute(...) method which returns the attribution result in a unified format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3892265aa383>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Convert the compute attrbution tensor into an image-like numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m attribution_dog=np.transpose(attribution_dog.squeeze().cpu().detach().numpy(),\n\u001b[0m\u001b[0;32m      6\u001b[0m                             (1,2,0))\n\u001b[0;32m      7\u001b[0m \u001b[1;34m\"\"\"np.transpose=> 전치 행렬 계산\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "# Convert the compute attrbution tensor into an image-like numpy array\n",
    "attribution_dog=np.transpose(attribution_dog.squeeze().cpu().detach().numpy(),\n",
    "                            (1,2,0))\n",
    "\"\"\"np.transpose=> 전치 행렬 계산\"\"\"\n",
    "\"\"\"\n",
    ".squeeze(배열, 축)=> 지정도니 축의 차원을 축소할 수 있음\n",
    "만약, 차원 축소 함수에 축을 입력하지 않으면, 1차원 배열로 축소함.\n",
    "\"\"\"\n",
    "\"\"\".detach(): 연산 기록으로 부터 분리, 이후 연산들이 추적되는 것을 방지함\"\"\"\n",
    "\n",
    "# *****************************************************\n",
    "\"\"\"??AttributeError: 'numpy.ndarray' object has no attribute 'cpu'\"\"\"\n",
    "# *****************************************************\n",
    "\n",
    "vis_types=[\"heat_map\",\"original_image\"]\n",
    "vis_signs=[\"all\",\"all\"]\n",
    "\n",
    "# positive attribution indicates \n",
    "# that the presence of the area increases the prediction score\n",
    "\n",
    "# negative attribution indicates\n",
    "# distractor(산만, 어지럽힘) areas whose absence increases the score\n",
    "\n",
    "_=viz.visualize_image_attr_multiple(attribution_dog,\n",
    "                                   center_crop(img),\n",
    "                                   vis_types,\n",
    "                                   vis_signs,\n",
    "                                   [\"arrtibution for dog\",\"image\"],\n",
    "                                   show_colorbar=True)\n",
    "\n",
    "attribution_cat=np.transpose(attribution_cat.squeeze().cpu().detach().numpy(),\n",
    "                            (1,2,0))\n",
    "_=viz.visualize_image_attr_multiple(attribution_cat,\n",
    "                                       center_crop(img),\n",
    "                                       [\"heat_map\",\"original_image\"],\n",
    "                                       [\"all\",\"all\"],\n",
    "                                        [\"attribution for cat\",'image'],\n",
    "                                        show_colorbar=True\n",
    "                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
