{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20.07.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is beneficial to zero out gradients when building a neural network. This is because by default, **gradients are accumulated in buffers**(not overwritten) whenever **.backward()** is called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when training your neural network, models are able to increase their accuracy through **gradient decent**. In short, gradient descent is the process of **minimizing our loss(or error)** by tweaking the weights and biases in our model.  \n",
    "**torch.Tensor** is the central class of PyTorch. when you create a tensor, if you set its attribute **.requires_grad as True**, the package tracks all operations on it. This happens on subsequent backward passes.(후속 역행)  \n",
    "The gradient for this tensor will be accumulated into .grad attribute. The accumulation(or sum) of all the gradients is calculated when .backward() is called on the loss tensor.  \n",
    "**There are cases where it may be necessary to zero-out the gradients of a tensor. For example: when you start your training loop, you should zero out the gradients so that you can perform this tracking correctly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries for loading our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and normalize the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch features various built-in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                             transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "\n",
    "trainset=torchvision.datasets.CIFAR10(root='./data',train=True,\n",
    "                                     download=True,transform=transform)\n",
    "\n",
    "trainloader=torch.utils.data.DataLoader(trainset,batch_size=4,\n",
    "                                       shuffle=True,num_workers=2)\n",
    "\n",
    "testset=torchvision.datasets.CIFAR10(root='/data',train=False,\n",
    "                                    download=True,transform=transform)\n",
    "\n",
    "testloader=torch.utils.data.DataLoader(testset,batch_size=4,\n",
    "                                      shuffle=False, num_workers=2)\n",
    "\n",
    "classses=('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20.07.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1=nn.Conv2d(3,6,5)\n",
    "        self.pool=nn.MaxPool2d(2,2)\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        self.fc1=nn.Linear(16*5*5,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3=nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.pool(F.relu(self.conv1(x)))\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        x=x.view(-1,16*5*5)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Net()\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.SGD(net.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20.07.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.191\n",
      "[1,  4000] loss: 4.010\n",
      "[1,  6000] loss: 5.647\n",
      "[1,  8000] loss: 7.205\n",
      "[1, 10000] loss: 8.699\n",
      "[1, 12000] loss: 10.171\n",
      "[2,  2000] loss: 1.374\n",
      "[2,  4000] loss: 2.700\n",
      "[2,  6000] loss: 4.004\n",
      "[2,  8000] loss: 5.270\n",
      "[2, 10000] loss: 6.521\n",
      "[2, 12000] loss: 7.752\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): #loop over the dataset multiple times\n",
    "    \n",
    "    running_loss=0.0\n",
    "    for i ,data in enumerate(trainloader, 0):\n",
    "        #get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels=data\n",
    "        \n",
    "        #zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward + backward +optimize\n",
    "        outputs=net(inputs)\n",
    "        loss=criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print statistics\n",
    "        running_loss +=loss.item()\n",
    "        if i % 2000==1999: #print every 2000 mini-batch\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch +1, i+1, running_loss/2000))\n",
    "            running_losss=0.0\n",
    "            \n",
    "print('Finished Training')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
