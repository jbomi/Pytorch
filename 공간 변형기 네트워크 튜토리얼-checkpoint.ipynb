{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.ion() #interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#학습 데이터\n",
    "train_loader=torch.utils.data.DataLoader(datasets.MNIST\n",
    "                                         (root='.',train=True,download=True, \n",
    "                                          transform=transforms.Compose([\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize((0.1307,),(0.3081,))\n",
    "                                          ])),batch_size=64, shuffle=True, \n",
    "                                        num_workers=4)\n",
    "#데스트 데이터\n",
    "test_loader=torch.utils.data.DataLoader(datasets.MNIST(root='.',train=False,\n",
    "                                                      transform=transforms.Compose([\n",
    "                                                          transforms.ToTensor(),\n",
    "                                                          transforms.Normalize((0.1307,),(0.3081,))\n",
    "                                                      ])),batch_size=64, shuffle=True, \n",
    "                                       num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 공간 변형 네트워크 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1=nn.Conv2d(1,10,kernel_size=5)\n",
    "        self.conv2=nn.Conv2d(10,20,kernel_size=5)\n",
    "        self.conv2_drop=nn.Dropout2d()\n",
    "        self.fc1=nn.Linear(320,50)\n",
    "        self.fc2=nn.Linear(50,10)\n",
    "        \n",
    "        #Spatial transformer localization-network\n",
    "        self.localization=nn.Sequential(\n",
    "        nn.Conv2d(1,8,kernel_size=7),\n",
    "        nn.MaxPool2d(2,stride=2),\n",
    "        nn.ReLU(True),\n",
    "        nn.Conv2d(8,10,kernel_size=5),\n",
    "        nn.MaxPool2d(2,stride=2),\n",
    "        nn.ReLU(True))\n",
    "        \n",
    "        #Regressor for the 3*2 affine matrix\n",
    "        self.fc_loc=nn.Sequential(\n",
    "        nn.Linear(10*3*3,32),\n",
    "        nn.ReLU(True),\n",
    "        nn.Linear(32,3*2))\n",
    "        \n",
    "        #Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1,0,0,0,1,0], dtype=torch.float))\n",
    "\n",
    "        #Spatial transformer network forward function\n",
    "        def stn(self, x):\n",
    "            xs=self.localization(x)\n",
    "            xs=xs.view(-1,10*3*3)\n",
    "            theta=self.fc_loc(xs)\n",
    "            theta=theta.view(-1,2,3)\n",
    "            \n",
    "            grid=F.affine_grid(theta, x.size())\n",
    "            x=F.grid_sample(x,grid)\n",
    "            \n",
    "            return x\n",
    "        \n",
    "        def forward(self,x):\n",
    "            #transform the input\n",
    "            x=self.stn(x)\n",
    "            \n",
    "            #perform the usual forward pass\n",
    "            x=F.relu(F.max_pool2d(self.conv1(x),2))\n",
    "            x=F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2))\n",
    "            x=x.view(-1,320)\n",
    "            x=F.relu(self.fc1(x))\n",
    "            x=F.dropout(x,training=self.training)\n",
    "            x=self.fc2(x)\n",
    "            return F.log_softmax(x, dim=1)\n",
    "        \n",
    "model=Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.SGD(model.parameters(),lr=0.01)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target=data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output=model(data)\n",
    "        loss=F.nll_loss(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 500==0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx*len(data),\n",
    "            len(train_loader.dataset),\n",
    "            100.*batch_idx/len(train_loader),loss.item()))\n",
    "#MNIST에서 STN의 성능을 측정하는 간단한 테스트 절차\n",
    "\n",
    "def test():\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss=0\n",
    "        correct=0\n",
    "        for data, target in test_loader:\n",
    "            data, target=data.to(device), target.to(device)\n",
    "            output=model(data)\n",
    "            \n",
    "            #sum up batch loss\n",
    "            test_loss+=F.nll_loss(output,target,size_average=False).item()\n",
    "            #get the index of the max log_probabilty\n",
    "            pred=output.max(1,keepdim=True)[1]\n",
    "            correct+=pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "        test_loss/=len(test_loader.dataset)\n",
    "        pritn('\\nTest set: Average loss:{:.4f}, Accuracy: {}/{}({:.0f}%)\\n'\n",
    "             .format(test_loss,correct, len(test_loader.dataset),100.*correct/\n",
    "                    len(test_loader.dataset)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STN 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-1f5a136a3450>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-afe868f21f97>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \"\"\"\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def convert_image_np(inp):\n",
    "    \"\"\"Convert a Tensor to numpy image\"\"\"\n",
    "    inp=inp.numpy().transpose((1,2,0))\n",
    "    mean=np.array([0.485,0.456,0.406])\n",
    "    std=np.array([0.229,0.224,0.225])\n",
    "    inp=std*inp+mean\n",
    "    inp=np.clip(inp,0,1)\n",
    "    return inp\n",
    "\n",
    "#학습 후에 공간 변형 레이어의 출력을 시각화 하기 위해 STN을 사용하여\n",
    "# 입력 이미지 배치와 해당 변형 배치를 시각화 합니다\n",
    "\n",
    "def visualize_stn():\n",
    "    with torch.no_grad():\n",
    "        #Get a batch of training data\n",
    "        data=next(iter(test_loader))[0].to(device)\n",
    "        \n",
    "        input_tensor=data.cpu()\n",
    "        transformed_input_tensor=model.stn(data).cpu()\n",
    "        \n",
    "        in_grid=convert_image_np(torchvision.utils.make_grid(input_tensor))\n",
    "        \n",
    "        out_grid=convert_image_np(\n",
    "            torchvision.utils.make_grid(transformed_input_tensor))\n",
    "        \n",
    "        #Plot the result side_by_side\n",
    "        \n",
    "        f, axarr=plt.subplots(1,2)\n",
    "        axarr[0].imshow(in_grid)\n",
    "        axarr[0].set_title('Dataset Images')\n",
    "        \n",
    "        axarr[1].imshow(out_grid)\n",
    "        axarr[1].set_title('Transformed Images')\n",
    "        \n",
    "for epoch in range(1,20+1):\n",
    "    train(epoch)\n",
    "    test()\n",
    "        \n",
    "#일부 입력 배치에서 STN 변형 시각화\n",
    "\n",
    "visualize_stn()\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
